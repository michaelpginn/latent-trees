{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b0202f-1d8c-4289-9579-d181347ccc9c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-24T20:18:12.150463Z",
     "start_time": "2023-11-24T20:18:10.508283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"'man' [0.3333333333333333] | 'woman' [0.3333333333333333] | 'girl' [0.3333333333333333]\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PCFG, Nonterminal\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "def equal_production(terminals, total=1):\n",
    "    \"\"\"Shorthand to write a list of terminals that are all equally likely\"\"\"\n",
    "    terminals = terminals.split(' | ')\n",
    "    return ' | '.join([f\"'{terminal}' [{total/len(terminals)}]\" for terminal in terminals])\n",
    "\n",
    "equal_production('man | woman | girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62c8e58-e298-42b0-b811-1293931f6ac6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-24T20:18:12.305799Z",
     "start_time": "2023-11-24T20:18:12.150261Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Randomly generate sentences using CFG\n",
    "def weighted_choice(choices):\n",
    "    total = sum(w for c, w in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for c, w in choices:\n",
    "        if upto + w >= r:\n",
    "            return c\n",
    "        upto += w\n",
    "\n",
    "def generate_sentence(grammar, symbol=Nonterminal('S')):\n",
    "    productions = grammar.productions(lhs=symbol)\n",
    "    chosen_prod = weighted_choice([(prod, prod.prob()) for prod in productions])\n",
    "    \n",
    "    sentence = []\n",
    "    # print(symbol)\n",
    "    for sym in chosen_prod.rhs():\n",
    "        if isinstance(sym, Nonterminal):\n",
    "            sentence.extend(generate_sentence(grammar, sym))\n",
    "        else:\n",
    "            sentence.append(sym)\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "# Morphology\n",
    "from pyfoma import *\n",
    "\n",
    "fsts = {}\n",
    "fsts['lex'] = FST.re(\"[a-zA-Z\\+]*\")\n",
    "\n",
    "fsts['sib']       = FST.re(\"s|sh|z|zh|ch|x\")\n",
    "fsts['C']         = FST.re(\"[a-z] - [aeiou]\")\n",
    "fsts['sibrk']     = FST.re(\"$^rewrite('':e / $sib _ \\+ s)\", fsts)\n",
    "fsts['yrule']     = FST.re(\"$^rewrite(y:(ie) / $C _ \\+ s)\", fsts)\n",
    "fsts['cleanup']   = FST.re(\"$^rewrite(\\+:'')\")\n",
    "fsts['grammar']   = FST.re(\"$lex @ $sibrk @ $yrule @ $cleanup\", fsts)\n",
    "\n",
    "def fix_morphology(words):\n",
    "    \"\"\"Combines morpheme clusters into proper words using an FST\"\"\"\n",
    "    combined_words = []\n",
    "    for word in words:\n",
    "        if word[0] == \"+\":\n",
    "            combined_words[-1] += word\n",
    "        else:\n",
    "            combined_words.append(word)\n",
    "    return [list(fsts['grammar'].generate(word))[0] for word in combined_words]\n",
    "\n",
    "def sample_sentences(grammar, n):\n",
    "    sents = [generate_sentence(grammar) for _ in range(n)]\n",
    "    sents = [' '.join(fix_morphology(sent)) for sent in sents]\n",
    "    # sents = [sent.capitalize() + \".\" for sent in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3602393f-fd6b-4c30-828b-ef997fc8e5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T20:25:29.351619Z",
     "start_time": "2023-11-24T20:25:29.345555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['the dude walks',\n 'I hug them',\n 'those cats kiss those ducks and the ladies',\n 'the linguist that punches these asparaguses thinks',\n 'he fights a cat',\n 'they love a linguist',\n 'the physicist thinks',\n 'the girl laughs',\n 'I walk',\n 'those shiny small dogs and these ladies and those asparaguses and the dudes that run and the cats and those boys ponder',\n 'he thinks',\n 'these girls fight a cat',\n 'they ponder',\n 'those ladies run',\n 'the lady that runs punches those boys',\n 'the asparaguses that punch the ladies run',\n 'a asparagus that laughs runs',\n 'he runs',\n 'a linguist punches us',\n 'we run']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT      NP_acc [0.475] | VI      [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_common Rel_Sg [0.2] | N_common [0.6]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_common '+s' Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | asparagus | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(pcfg, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308f4216-02cf-4071-8a3f-d12b9b982a94",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-24T20:20:18.423119Z",
     "start_time": "2023-11-24T20:20:18.420783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['she walk',\n 'I kisses these cats',\n 'these ducks hugs those blue cheeses',\n 'a linguist punch you',\n 'I fights a cat',\n 'I hugs those rabbits',\n 'a linguist ponder',\n 'these turtles kisses us',\n 'these ladies hugs the linguist',\n 'I kicks those cheeses and these dogs and walks',\n 'the sparkling dudes runs',\n 'he hug those cats',\n 'she walk and love the dudes and these girls and punch you',\n 'she punch the dogs that kisses us',\n 'he laugh',\n 'they ponders',\n 'you fights us',\n 'she ponder',\n 'those cats that punches the dog that walk loves us',\n 'I loves a cat']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement_violations = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT      NP_acc [0.475] | VI      [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_common Rel_Sg [0.15] | N_common [0.65]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_common '+s' Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | rutabaga | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(agreement_violations, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b120a2a8-57d4-44a1-9ac0-3f0fcc12c9de",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-24T20:37:13.888360Z",
     "start_time": "2023-11-24T20:37:06.647671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Stringifying the column:   0%|          | 0/4000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b5b2cd93b70499c8cc8c6397c4331c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting to class labels:   0%|          | 0/4000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a661b827f94b4c2fba6323b830362c72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6251fd4c328048ebb4838f34199f4193"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7eb99e4be0c473c930c46b71bbb9150"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af68089731244c46a7f8ddec9676669e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/547 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eec222f0b43b4c1db66c8194b7ddcd4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "random.seed(1)\n",
    "valid_num = 2000\n",
    "invalid_num = 2000\n",
    "valid = sample_sentences(pcfg, valid_num)\n",
    "invalid = sample_sentences(agreement_violations, invalid_num)\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({\"text\": valid + invalid, \"labels\": [1] * valid_num + [0] * invalid_num}).shuffle()\n",
    "\n",
    "dataset = dataset.class_encode_column('labels')\n",
    "dataset.train_test_split(test_size=0.3, stratify_by_column='labels')\n",
    "dataset.push_to_hub(\"michaelginn/latent-trees-agreement-ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_linear_heuristic(sentence: str):\n",
    "    for word in sentence.split(' '):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

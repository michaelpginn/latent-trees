{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b0202f-1d8c-4289-9579-d181347ccc9c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-27T20:45:22.211199Z",
     "start_time": "2023-10-27T20:45:21.270299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"'man' [0.3333333333333333] | 'woman' [0.3333333333333333] | 'girl' [0.3333333333333333]\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PCFG, Nonterminal\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "def equal_production(terminals, total=1):\n",
    "    \"\"\"Shorthand to write a list of terminals that are all equally likely\"\"\"\n",
    "    terminals = terminals.split(' | ')\n",
    "    return ' | '.join([f\"'{terminal}' [{total/len(terminals)}]\" for terminal in terminals])\n",
    "\n",
    "equal_production('man | woman | girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62c8e58-e298-42b0-b811-1293931f6ac6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-27T20:45:22.472217Z",
     "start_time": "2023-10-27T20:45:22.322511Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Randomly generate sentences using CFG\n",
    "def weighted_choice(choices):\n",
    "    total = sum(w for c, w in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for c, w in choices:\n",
    "        if upto + w >= r:\n",
    "            return c\n",
    "        upto += w\n",
    "\n",
    "def generate_sentence(grammar, symbol=Nonterminal('S')):\n",
    "    productions = grammar.productions(lhs=symbol)\n",
    "    chosen_prod = weighted_choice([(prod, prod.prob()) for prod in productions])\n",
    "    \n",
    "    sentence = []\n",
    "    # print(symbol)\n",
    "    for sym in chosen_prod.rhs():\n",
    "        if isinstance(sym, Nonterminal):\n",
    "            sentence.extend(generate_sentence(grammar, sym))\n",
    "        else:\n",
    "            sentence.append(sym)\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "# Morphology\n",
    "from pyfoma import *\n",
    "\n",
    "fsts = {}\n",
    "fsts['lex'] = FST.re(\"[a-zA-Z\\+]*\")\n",
    "\n",
    "fsts['sib']       = FST.re(\"s|sh|z|zh|ch|x\")\n",
    "fsts['C']         = FST.re(\"[a-z] - [aeiou]\")\n",
    "fsts['sibrk']     = FST.re(\"$^rewrite('':e / $sib _ \\+ s)\", fsts)\n",
    "fsts['yrule']     = FST.re(\"$^rewrite(y:(ie) / $C _ \\+ s)\", fsts)\n",
    "fsts['cleanup']   = FST.re(\"$^rewrite(\\+:'')\")\n",
    "fsts['grammar']   = FST.re(\"$lex @ $sibrk @ $yrule @ $cleanup\", fsts)\n",
    "\n",
    "def fix_morphology(words):\n",
    "    \"\"\"Combines morpheme clusters into proper words using an FST\"\"\"\n",
    "    combined_words = []\n",
    "    for word in words:\n",
    "        if word[0] == \"+\":\n",
    "            combined_words[-1] += word\n",
    "        else:\n",
    "            combined_words.append(word)\n",
    "    return [list(fsts['grammar'].generate(word))[0] for word in combined_words]\n",
    "\n",
    "def sample_sentences(grammar, n):\n",
    "    sents = [generate_sentence(grammar) for _ in range(n)]\n",
    "    sents = [' '.join(fix_morphology(sent)) for sent in sents]\n",
    "    # sents = [sent.capitalize() + \".\" for sent in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3602393f-fd6b-4c30-828b-ef997fc8e5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T20:45:23.494620Z",
     "start_time": "2023-10-27T20:45:23.491100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['he loves those happy dudes',\n 'we ponder',\n 'she kicks them',\n 'those girls punch a turtle',\n 'we love a wug',\n 'the cat laughs',\n 'these mad ladies love us',\n 'a dog thinks',\n 'we hug you',\n 'I think',\n 'those cats kick the rabbits',\n 'she fights me',\n 'she fights me',\n 'these physicists fight these cats',\n 'a small asparagus that hugs a cat and ponders kisses us',\n 'the asparaguses laugh',\n 'you ponder',\n 'those rabbits ponder',\n 'a duck fights them',\n 'the turtle that fights the boys punches the bird']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT      NP_acc [0.475] | VI      [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_bar_common_Sg Rel_Sg [0.15] | N_common [0.65]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_bar_common_Pl Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | asparagus | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(pcfg, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308f4216-02cf-4071-8a3f-d12b9b982a94",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-27T20:45:24.590514Z",
     "start_time": "2023-10-27T20:45:24.583154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['they kisses us',\n 'we kisses these dogs',\n 'she kick a dog',\n 'the small ducks that loves a girl laughs',\n 'I punches them',\n 'they punches them',\n 'those boys thinks',\n 'those dogs walks',\n 'the physicists fights these ducks',\n 'she run',\n 'the wugs thinks',\n 'those rutabagas hugs them and laughs',\n 'she think',\n 'the wugs fights the shiny small big linguists',\n 'those rutabagas walks',\n 'I walks',\n 'he run',\n 'he walk',\n 'the cheeses fights me and ponders and ponders',\n 'these rutabagas ponders']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement_violations = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT      NP_acc [0.475] | VI      [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_bar_common_Sg Rel_Sg [0.15] | N_common [0.65]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_bar_common_Pl Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | rutabaga | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(agreement_violations, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b120a2a8-57d4-44a1-9ac0-3f0fcc12c9de",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-27T21:09:31.036767Z",
     "start_time": "2023-10-27T21:09:26.738006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c11b6837d6240c2bcc62122090a9768"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f72b1ad4344d3ebe468b3024705485"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36562483e7dc49f9bc5562f6d95f985e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b9cba8b85fd473abbeeeaded414fe82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99870579e87042faae1c421e30554780"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "539362be42644422b34b6c90719d278d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "valid_num = 2000\n",
    "invalid_num = 200\n",
    "valid = sample_sentences(pcfg, valid_num)\n",
    "invalid = sample_sentences(agreement_violations, invalid_num)\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({\"text\": valid + invalid, \"label\": [1] * valid_num + [0] * invalid_num}).shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "dataset.push_to_hub(\"michaelginn/latent-trees-agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

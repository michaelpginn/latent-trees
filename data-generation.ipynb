{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b0202f-1d8c-4289-9579-d181347ccc9c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-27T20:45:22.211199Z",
     "start_time": "2023-10-27T20:45:21.270299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"'man' [0.3333333333333333] | 'woman' [0.3333333333333333] | 'girl' [0.3333333333333333]\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PCFG, Nonterminal\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "def equal_production(terminals, total=1):\n",
    "    \"\"\"Shorthand to write a list of terminals that are all equally likely\"\"\"\n",
    "    terminals = terminals.split(' | ')\n",
    "    return ' | '.join([f\"'{terminal}' [{total/len(terminals)}]\" for terminal in terminals])\n",
    "\n",
    "equal_production('man | woman | girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c62c8e58-e298-42b0-b811-1293931f6ac6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-29T23:18:14.684330Z",
     "start_time": "2023-10-29T23:18:14.564657Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Randomly generate sentences using CFG\n",
    "def weighted_choice(choices):\n",
    "    total = sum(w for c, w in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for c, w in choices:\n",
    "        if upto + w >= r:\n",
    "            return c\n",
    "        upto += w\n",
    "\n",
    "def generate_sentence(grammar, symbol=Nonterminal('S')):\n",
    "    productions = grammar.productions(lhs=symbol)\n",
    "    chosen_prod = weighted_choice([(prod, prod.prob()) for prod in productions])\n",
    "    \n",
    "    sentence = []\n",
    "    # print(symbol)\n",
    "    for sym in chosen_prod.rhs():\n",
    "        if isinstance(sym, Nonterminal):\n",
    "            sentence.extend(generate_sentence(grammar, sym))\n",
    "        else:\n",
    "            sentence.append(sym)\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "# Morphology\n",
    "from pyfoma import *\n",
    "\n",
    "fsts = {}\n",
    "fsts['lex'] = FST.re(\"[a-zA-Z\\+]*\")\n",
    "\n",
    "fsts['sib']       = FST.re(\"s|sh|z|zh|ch|x\")\n",
    "fsts['C']         = FST.re(\"[a-z] - [aeiou]\")\n",
    "fsts['sibrk']     = FST.re(\"$^rewrite('':e / $sib _ \\+ s)\", fsts)\n",
    "fsts['yrule']     = FST.re(\"$^rewrite(y:(ie) / $C _ \\+ s)\", fsts)\n",
    "fsts['cleanup']   = FST.re(\"$^rewrite(\\+:'')\")\n",
    "fsts['grammar']   = FST.re(\"$lex @ $sibrk @ $yrule @ $cleanup\", fsts)\n",
    "\n",
    "def fix_morphology(words):\n",
    "    \"\"\"Combines morpheme clusters into proper words using an FST\"\"\"\n",
    "    combined_words = []\n",
    "    for word in words:\n",
    "        if word[0] == \"+\":\n",
    "            combined_words[-1] += word\n",
    "        else:\n",
    "            combined_words.append(word)\n",
    "    return [list(fsts['grammar'].generate(word))[0] for word in combined_words]\n",
    "\n",
    "def sample_sentences(grammar, n):\n",
    "    sents = [generate_sentence(grammar) for _ in range(n)]\n",
    "    sents = [' '.join(fix_morphology(sent)) for sent in sents]\n",
    "    # sents = [sent.capitalize() + \".\" for sent in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3602393f-fd6b-4c30-828b-ef997fc8e5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T23:18:19.283260Z",
     "start_time": "2023-10-29T23:18:19.277058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['they run',\n 'the dog loves a duck',\n 'the red rabbits kiss the cats',\n 'he laughs',\n 'the dudes and these mad cats kiss these girls and the ducks and those physicists',\n 'I run',\n 'I laugh',\n 'I ponder',\n 'these wugs kick the turtle',\n 'he laughs and ponders',\n 'we run',\n 'she laughs',\n 'I kick a cat',\n 'those mad physicists and those blue physicists ponder',\n 'he kisses these happy boys and those physicists',\n 'she punches me',\n 'they laugh',\n 'a girl ponders',\n 'a boy hugs a duck',\n 'a blue cheese ponders']"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT      NP_acc [0.475] | VI      [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_common Rel_Sg [0.15] | N_common [0.65]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_common Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | asparagus | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(pcfg, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "308f4216-02cf-4071-8a3f-d12b9b982a94",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-29T23:18:27.665068Z",
     "start_time": "2023-10-29T23:18:27.659613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['she laugh',\n 'a cat laugh',\n 'the cat punch a cat',\n 'those linguists ponders',\n 'they kisses us',\n 'she walk',\n 'those mad boys fights those girls and the birds',\n 'a mad duck ponder',\n 'he punch the lady',\n 'they runs',\n 'he hug those linguists',\n 'she think',\n 'these dudes punches a lady that think',\n 'she think',\n 'they laughs',\n 'he kiss those rutabagas',\n 'she hug those dogs',\n 'those wugs and those cats and these small blue boy that walks kisses the cats',\n 'she kick you',\n 'the bird ponder']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement_violations = PCFG.fromstring(f\"\"\"\n",
    "S             -> NP_3Sg_nom VP_3Sg [0.5] | NP_nom VP [0.5]\n",
    "\n",
    "VP_3Sg        -> VT      NP_acc [0.475] | VI      [0.475] | VP_3Sg 'and' VP_3Sg [0.05]\n",
    "VP            -> VT '+s' NP_acc [0.475] | VI '+s' [0.475] | VP     'and' VP     [0.05]\n",
    "\n",
    "NP_3Sg_nom    -> 'he' [0.25] | 'she' [0.25] | NP_common_Sg [0.5]\n",
    "NP_common_Sg  -> Det_Sg N_bar_common_Sg [1]\n",
    "Det_Sg        -> {equal_production('the | a')}\n",
    "\n",
    "NP_nom        -> {equal_production('I | you | we | they', total=0.5)} | NP_common_Pl [0.5]\n",
    "NP_common_Pl  -> Det_Pl N_bar_common_Pl [0.8] | NP_common_Pl 'and' NP_common_Pl [0.2]\n",
    "Det_Pl        -> {equal_production('the | those | these')}\n",
    "\n",
    "NP_acc        -> {equal_production('me | you | us | them', total=0.30)} | NP_common_Pl [0.35] | NP_common_Sg [0.35]\n",
    "\n",
    "N_bar_common_Sg  -> Adj N_bar_common_Sg [0.2] | N_common Rel_Sg [0.15] | N_common [0.65]\n",
    "N_bar_common_Pl  -> Adj N_bar_common_Pl [0.2] | N_common Rel_Pl [0.15] | N_common '+s' [0.65]\n",
    "N_common      -> {equal_production('girl | boy | cat | turtle | rutabaga | duck | cheese | dude | rabbit | wug | linguist | physicist | lady | dog | cat | bird')}\n",
    "\n",
    "Rel_Sg         -> 'that' VP_3Sg [1]\n",
    "Rel_Pl         -> 'that' VP [1]\n",
    "\n",
    "VI            -> {equal_production('run | walk | think | laugh | ponder')}\n",
    "VT            -> {equal_production('kick | kiss | hug | punch | fight | love')}\n",
    "\n",
    "Adj           -> {equal_production('big | small | happy | mad | red | blue | sparkling | shiny')}\n",
    "\"\"\")\n",
    "\n",
    "sample_sentences(agreement_violations, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b120a2a8-57d4-44a1-9ac0-3f0fcc12c9de",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-29T23:18:39.108246Z",
     "start_time": "2023-10-29T23:18:33.783462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "747f0fef6a0d4645b9eb690e2162a6b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4efe27cbab3f49d5a0b1fb9d6ae28641"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfbb1f19eed44affa9dea22f5242215e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "565edb8d9b2047c99d591b67d59f2f27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd2ae34a2cf24c6cb50c446bf68df8db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a811ce5ca9964295ae031fe6b11d3428"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/579 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f592b7653c4f4eda9dae5bec6ee2bed5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "valid_num = 2000\n",
    "invalid_num = 200\n",
    "valid = sample_sentences(pcfg, valid_num)\n",
    "invalid = sample_sentences(agreement_violations, invalid_num)\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({\"text\": valid + invalid, \"label\": [1] * valid_num + [0] * invalid_num}).shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "dataset.push_to_hub(\"michaelginn/latent-trees-agreement\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

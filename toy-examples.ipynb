{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T04:46:49.599101Z",
     "start_time": "2023-10-30T04:46:43.649860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/583 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d451231041c24840b65a72c1284248cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1540 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7db451113b3a4a1e938d210c58b81d74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/660 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58132c19500d4233a2e775bc4fa2cd0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1540\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 660\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from src.WhitespaceTokenizer import WhitespaceTokenizer\n",
    "import datasets\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "dataset = datasets.load_dataset(\"michaelginn/latent-trees-agreement\")\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "tokenizer.learn_vocab([row['text'] for row in dataset['train']])\n",
    "dataset = dataset.map(tokenizer.tokenize_batch, batched=True, load_from_cache_file=False)\n",
    "print(dataset)\n",
    "\n",
    "config = BertConfig(vocab_size=tokenizer.vocab_size, num_labels=2, max_position_embeddings=tokenizer.model_max_length)\n",
    "model = BertForSequenceClassification(config=config).to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesper/miniforge3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 0 | Loss: 0.6844738721847534\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 1 | Loss: 0.6032574772834778\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 2 | Loss: 0.688709020614624\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 3 | Loss: 0.5118123888969421\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 4 | Loss: 0.6379901170730591\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 5 | Loss: 0.5188990831375122\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 6 | Loss: 0.35225194692611694\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 7 | Loss: 0.3565382957458496\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 8 | Loss: 0.3622358441352844\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 9 | Loss: 0.2323547601699829\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 10 | Loss: 0.25429606437683105\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 11 | Loss: 0.2174314558506012\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 12 | Loss: 0.19011393189430237\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 13 | Loss: 0.12362507730722427\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 14 | Loss: 0.10428424179553986\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 15 | Loss: 0.08784057945013046\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 16 | Loss: 0.07751313596963882\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 17 | Loss: 0.0504145547747612\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 18 | Loss: 0.045610908418893814\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 19 | Loss: 0.04136411473155022\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 20 | Loss: 0.03008308820426464\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 21 | Loss: 0.021775389090180397\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 22 | Loss: 0.021213781088590622\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 23 | Loss: 0.017761100083589554\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 24 | Loss: 0.013185478746891022\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 25 | Loss: 0.011065015569329262\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 26 | Loss: 0.008036768063902855\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 27 | Loss: 0.008835196495056152\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 28 | Loss: 0.009224443696439266\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 29 | Loss: 0.007368737366050482\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 30 | Loss: 0.00854310393333435\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 31 | Loss: 0.005555479321628809\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 32 | Loss: 0.006220178212970495\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 33 | Loss: 0.005001407582312822\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 34 | Loss: 0.006318528670817614\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 35 | Loss: 0.004596625454723835\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 36 | Loss: 0.00409634318202734\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 37 | Loss: 0.004855727776885033\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 38 | Loss: 0.0031960015185177326\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 39 | Loss: 0.0046683549880981445\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 40 | Loss: 0.003357895649969578\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 41 | Loss: 0.00387625303119421\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 42 | Loss: 0.004228058736771345\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 43 | Loss: 0.003713423851877451\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 44 | Loss: 0.0030740206129848957\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 45 | Loss: 0.0028052921406924725\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 46 | Loss: 0.0031954681035131216\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 47 | Loss: 0.0031346057076007128\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 48 | Loss: 0.0025500385090708733\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 49 | Loss: 0.003437742590904236\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 50 | Loss: 0.0026734615676105022\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 51 | Loss: 0.002778340596705675\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 52 | Loss: 0.0029774452559649944\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 53 | Loss: 0.0023967428132891655\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 54 | Loss: 0.00314925704151392\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 55 | Loss: 0.0019836232531815767\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 56 | Loss: 0.0022428592201322317\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 57 | Loss: 0.0020199851132929325\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n",
      "Epoch: 58 | Loss: 0.002319319173693657\n",
      "tensor([[ 1,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 1, 57, 37,  ...,  0,  0,  0]], device='mps:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 35\u001B[0m\n\u001B[1;32m     32\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     33\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 35\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1556\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1548\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1550\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m   1553\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1554\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1556\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1561\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1562\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1563\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1566\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1568\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   1570\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1018\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1009\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m   1011\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m   1012\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1013\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1016\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m   1017\u001B[0m )\n\u001B[0;32m-> 1018\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1020\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1025\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1030\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1031\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    598\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    599\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    600\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    604\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    605\u001B[0m     )\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 607\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    611\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    612\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    614\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    615\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:493\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    483\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    491\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[1;32m    492\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 493\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:423\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    414\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    415\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    421\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    422\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m--> 423\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[1;32m    433\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:361\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m     attention_probs \u001B[38;5;241m=\u001B[39m attention_probs \u001B[38;5;241m*\u001B[39m head_mask\n\u001B[0;32m--> 361\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_probs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue_layer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m    364\u001B[0m new_context_layer_shape \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_head_size,)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "train_epochs = 100\n",
    "\n",
    "device='mps'\n",
    "\n",
    "# toy_data = [dataset['train'][0], dataset['train'][26]]\n",
    "def collate(batch):\n",
    "    # Convert lists to arrays here and then to tensors\n",
    "    input_ids = torch.tensor(np.array([item['input_ids'] for item in batch]), device=device)\n",
    "    labels = torch.tensor(np.array([item['label'] for item in batch]), device=device)\n",
    "    attention_mask = torch.tensor(np.array([item['attention_mask'] for item in batch]), device=device)\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels,\n",
    "        'attention_mask': attention_mask\n",
    "    }\n",
    "\n",
    "toy_data = dataset['train'].select([0, 26])\n",
    "train_dataloader = DataLoader(toy_data, batch_size=2, collate_fn=collate)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        print(batch['input_ids'])\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     output_dir=f\"../training-checkpoints\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     save_total_limit=3,\n",
    "#     num_train_epochs=train_epochs,\n",
    "#     load_best_model_at_end=False,\n",
    "#     logging_strategy='steps',\n",
    "#     logging_steps=1,\n",
    "#     report_to='wandb'\n",
    "# )\n",
    "#\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     args,\n",
    "#     train_dataset=toy_data,\n",
    "#     eval_dataset=toy_data,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T03:40:05.898651Z",
     "start_time": "2023-10-30T03:39:25.120337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "48"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest = 0\n",
    "\n",
    "for row in dataset['train']:\n",
    "    tokens = len(tokenizer.tokenize(row['text']))\n",
    "    if tokens > longest:\n",
    "        longest = tokens\n",
    "longest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T04:48:54.747503Z",
     "start_time": "2023-10-30T04:48:54.172431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
